{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import inspect\n",
    "\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import sklearn.model_selection\n",
    "\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.metrics import Loss, Accuracy\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "torch.set_num_threads(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "valid_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                       transforms.CenterCrop(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "train_dataset = datasets.ImageFolder('gestos/train', transform=train_transforms)\n",
    "valid_dataset = datasets.ImageFolder('gestos/valid', transform=valid_transforms)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=6)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True, progress=True)\n",
    "model.eval()\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "neuronas = model.fc.in_features   #512\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(neuronas, 128),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(128,4),\n",
    "    torch.nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "max_epochs = 100\n",
    "device = torch.device('cpu')\n",
    "\n",
    "\n",
    "def train_one_step(engine, batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    yhat = model.forward(x)\n",
    "    loss = criterion(yhat, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item() # Este output puede llamar luego como trainer.state.output\n",
    "\n",
    "\n",
    "def evaluate_one_step(engine, batch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        yhat = model.forward(x)\n",
    "        loss = criterion(yhat, y)\n",
    "        return yhat, y\n",
    "    \n",
    "\n",
    "trainer = Engine(train_one_step)\n",
    "evaluator = Engine(evaluate_one_step)\n",
    "metrics = {'Loss': Loss(criterion), 'Acc': Accuracy()}\n",
    "for name, metric in metrics.items():\n",
    "    metric.attach(evaluator, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SummaryWriter(log_dir=f'/tmp/tensorboard/prerun' + runtime) as writer:\n",
    "    \n",
    "    @trainer.on(Events.EPOCH_COMPLETED(every=1)) # Cada 1 epocas\n",
    "    def log_results(engine):\n",
    "        # Evaluo el conjunto de entrenamiento\n",
    "        evaluator.run(train_loader) \n",
    "        writer.add_scalar(\"train/loss\", evaluator.state.metrics['Loss'], engine.state.epoch)\n",
    "        writer.add_scalar(\"train/accy\", evaluator.state.metrics['Acc'], engine.state.epoch)\n",
    "        \n",
    "        evaluator.run(valid_loader) \n",
    "        writer.add_scalar(\"valid/loss\", evaluator.state.metrics['Loss'], engine.state.epoch)\n",
    "        writer.add_scalar(\"valid/accy\", evaluator.state.metrics['Acc'], engine.state.epoch)\n",
    "        #print(\"Época: \", engine.state.epoch,\"   Demora: \", time.time()-seconds, \"[seg]    \", \"Loss: \", evaluator.state.output[2])\n",
    "    # Guardo el mejor modelo en validación\n",
    "    best_model_handler = ModelCheckpoint(dirname=folder+runtime+'/bests', require_empty=False, filename_prefix=\"best\", n_saved=5,\n",
    "                                         score_function=lambda engine: -engine.state.metrics['Loss'],\n",
    "                                         score_name=\"val_loss\")\n",
    "    # Lo siguiente se ejecuta cada ves que termine el loop de validación\n",
    "    evaluator.add_event_handler(Events.COMPLETED, \n",
    "                                best_model_handler, {'ResNet18': model})\n",
    "    trainer.run(train_loader, max_epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                       transforms.CenterCrop(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "test_data = datasets.ImageFolder('gestos/test', transform=test_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.load_state_dict(torch.load(folder+runtime+'bests/'+file, map_location=torch.device('cpu')))\n",
    "\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=256)\n",
    "\n",
    "test_targets = np.array(test_data.targets)\n",
    "prediction_test = []\n",
    "\n",
    "\n",
    "for mbdata, label in test_loader:\n",
    "\n",
    "    logits = model.forward(mbdata)\n",
    "    prediction_test.append(logits.argmax(dim=1).detach().numpy())\n",
    "prediction_test = np.concatenate(prediction_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm.append(confusion_matrix(test_targets, prediction_test))\n",
    "display(cm)\n",
    "report = classification_report(test_targets, prediction_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
